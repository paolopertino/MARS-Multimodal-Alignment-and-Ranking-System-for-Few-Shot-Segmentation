## Preparing MARS checkpoints
Download under this folder (`<PATH_TO_REPO>/models`) all the checkpoints of the models.

- [Segment Anything Model - ViT-H/16](<https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth>)
- [DINOv2 Pretrained ViT-L/14](<https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth>)
- [DINOv2 Pretrained ViT-L/14 with 4 register tokens](<https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_reg4_pretrain.pth>)
- [AlphaCLIP CLIP-L/14@336px](<https://drive.google.com/file/d/1dUq1deeLcou26RuxZbBG57m2ALPWev6-/view?usp=drive_link>)
- [CLIP-B/16](<https://openaipublic.azureedge.net/clip/models/5806e77cd80f8b59890b7e101eabd078d9fb84e6937f9e85e4ecb61988df416f/ViT-B-16.pt>)

The Vision Language Model, `ViP-LLaVA` has been taken from [huggingface](<https://huggingface.co/llava-hf/vip-llava-7b-hf>).