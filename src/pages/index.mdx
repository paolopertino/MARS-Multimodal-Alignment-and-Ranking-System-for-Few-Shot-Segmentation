---
layout: ../layouts/Layout.astro
title: MARS: a Multimodal Alignment and Ranking System for Few-Shot Segmentation
description: Project page for the paper "MARS: a Multimodal Alignment and Ranking System for Few-Shot Segmentation"
favicon: favicon.svg
thumbnail: screenshot-light.png
---

import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";

import { ImageComparison } from "../components/ImageComparison.tsx";

import outside from "../assets/outside.mp4";
import transformer from "../assets/transformer.webp";
import Splat from "../components/Splat.tsx"
import dogsDiffc from "../assets/dogs-diffc.png"
import dogsTrue from "../assets/dogs-true.png"


import CodeBlock from "../components/CodeBlock.astro";
import Table from "../components/Table.astro";
export const components = {pre: CodeBlock, table: Table}

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Stefano Samele",
      url: "https://scholar.google.com/citations?user=9eINCUAAAAAJ&hl=it",
      institution: "Politecnico di Milano",
      notes: ["*"],
    },
    {
      name: "Nico Catalano",
      url: "https://scholar.google.com/citations?user=ZrGxR2YAAAAJ&hl=en",
      institution: "Politecnico di Milano",
      notes: ["*"],
    },
    {
      name: "Paolo Pertino",
      url: "https://scholar.google.com/citations?user=sGhbVfEAAAAJ&hl=en",
      institution: "Politecnico di Milano",
      notes: ["*"],
    },
    {
      name: "Matteo Matteucci",
      url: "https://scholar.google.it/citations?user=PdbEg5YAAAAJ&hl=it",
      institution: "Politecnico di Milano",
    },
  ]}
  conference="Conference Name"
  notes={[
    {
      symbol: "*",
      text: "Equal contribution",
    },
    {
      symbol: "â€ ",
      text: "author note two",
    },
  ]}
  links={[
    {
      name: "Paper",
      url: "",
      icon: "ri:file-pdf-2-line",
    },
    {
      name: "Code",
      url: "https://github.com/paolopertino/MARS-Multimodal-Alignment-and-Ranking-System-for-Few-Shot-Segmentation",
      icon: "ri:github-line",
    },
    {
      name: "arXiv",
      url: "https://arxiv.org/abs/2504.07942",
      icon: "academicons:arxiv",
    },
    {
      name: "Bluesky",
      url: "",
      icon: "ri:bluesky-line"
    }
  ]}
  />

<Video source={outside} />

<HighlightedSection>

## Abstract

Current Few Shot Segmentation literature lacks a mask selection method that goes beyond visual similarity between the query and example images, leading to suboptimal predictions. We present MARS, a plug-and-play ranking system that leverages multimodal cues to filter and merge mask proposals robustly. Starting from a set of mask predictions for a single query image, we score, filter, and merge them to improve results. Proposals are evaluated using multimodal scores computed at local and global levels. Extensive experiments on COCO-20i, Pascal-5i, LVIS-92i, and FSS-1000 demonstrate that integrating all four scoring components is crucial for robust ranking, validating our contribution. As MARS can be effortlessly integrated with various mask proposal systems, we deploy it across a wide range of top-performer methods and achieve new state-of-the-art results on multiple existing benchmarks. Code will be available upon acceptance.

</HighlightedSection>

## Figures

Use the figure component to display images, videos, equations, or any other element, with an optional caption.

<Figure>
  <Image slot="figure" source={transformer} altText="Diagram of the transformer deep learning architecture." />
  <span slot="caption">Diagram of the transformer deep learning architecture.</span>
</Figure>

## Image comparison slider

An interactive, accessible slider component with keyboard navigation.
<Figure>
  <ImageComparison slot="figure" client:load imageUrlOne={dogsDiffc.src} imageUrlTwo={dogsTrue.src} altTextOne="Photo of two dogs running side-by-side in shallow water, lossily compressed using the DiffC algorithm" altTextTwo="Original photo of two dogs running side-by-side in shallow water" />
  <span slot="caption">A photo of two dogs running side-by-side in shallow water, lossily compressed using the <a href="https://jeremyiv.github.io/diffc-project-page/">DiffC algorithm</a>.</span>
</Figure>

## Two columns

Use the two columns component to display two columns of content. In this example, the first column contains a figure with a YouTube video and the second column contains a figure with a custom [React](https://react.dev/) component. By default, they display side by side, but if the screen is narrow enough (for example, on mobile), they're arranged vertically.

<TwoColumns>
  <Figure slot="left">
    <YouTubeVideo slot="figure" videoId="wjZofJX0v4M" />
    <span slot="caption">Take a look at this YouTube video.</span>
  </Figure>
  <Figure slot="right">
    <Splat slot="figure" client:idle />
    <span slot="caption">Now look at this <a href="https://en.wikipedia.org/wiki/Gaussian_splatting">Gaussian splat</a>, rendered with a React component.</span>
  </Figure>
</TwoColumns>

## Heading levels

Use headings to divide your content into sections.

### Heading 3

Go down a level to heading 3...

#### Heading 4

...and down again to heading 4.

## LaTeX

You can also add LaTeX formulas, rendered during the build process using [KaTeX](https://katex.org/) so they're quick to load for visitors of your project page. You can write them inline, like this: <LaTeX inline formula="a^2 + b^2 = c^2" />. Or, you can write them as a block:

<LaTeX formula="\int_a^b f(x) dx" />

## Tables

You can add simple tables using [GitHub Flavored Markdown syntax](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/organizing-information-with-tables):

| Model | Accuracy | F1 score | Training time (hours) |
| :--- | :---: | :---: | :---: |
| BERT-base | 0.89 | 0.87 | 4.5 |
| RoBERTa-large | 0.92 | 0.91 | 7.2 |
| DistilBERT | 0.86 | 0.84 | 2.1 |
| XLNet | 0.90 | 0.89 | 6.8 |

## BibTeX citation

```bibtex
@misc{roman2024academic,
  author = "{Roman Hauksson}",
  title = "Academic Project Page Template",
  year = "2024",
  howpublished = "\url{https://research-template.roman.technology}",
}
```